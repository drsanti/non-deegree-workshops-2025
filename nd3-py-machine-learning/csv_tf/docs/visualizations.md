# CSV_TF Module Visualization Documentation

This document describes all plots and visualizations generated by the CSV_TF module scripts for motor vibration data analysis.

## Table of Contents

- [Training Visualizations](#training-visualizations)
- [Testing Visualizations](#testing-visualizations)
- [Validation Visualizations](#validation-visualizations)
- [Plot Interpretation Guide](#plot-interpretation-guide)

---

## Training Visualizations

### LSTM Model Training

**Script**: `train_lstm.py`  
**Output Files**:
- `output/lstm_training_history.png`
- `output/lstm_training_confusion_matrix.png`

#### 1. Training History Plot

**File**: `output/lstm_training_history.png`

A 1×2 subplot grid showing training progress:

1. **Model Loss** (Left Subplot)
   - **X-axis**: Epoch number
   - **Y-axis**: Loss value
   - **Lines**:
     - Training Loss (solid line, blue)
     - Validation Loss (dashed line, orange)
   - **Purpose**: Shows how the model's error decreases during training
   - **Interpretation**:
     - Decreasing loss: Model is learning
     - Large gap between train/val: Possible overfitting
     - Loss plateau: Model has converged

2. **Model Accuracy** (Right Subplot)
   - **X-axis**: Epoch number
   - **Y-axis**: Accuracy (0-1 or 0-100%)
   - **Lines**:
     - Training Accuracy (solid line, blue)
     - Validation Accuracy (dashed line, orange)
   - **Purpose**: Shows classification performance improvement
   - **Interpretation**:
     - Increasing accuracy: Model performance improving
     - 100% accuracy: Perfect classification (common with synthetic data)
     - Accuracy plateau: Maximum performance reached

**Model Configuration**:
- Architecture: LSTM (32 units) → Dense (16 units) → Dense (4 units, softmax)
- Optimizer: Adam (learning_rate=0.001)
- Loss: sparse_categorical_crossentropy
- Epochs: 100 (with early stopping, patience=15)
- Batch size: 16

#### 2. Training Confusion Matrix

**File**: `output/lstm_training_confusion_matrix.png`

- **Type**: 4×4 heatmap
- **Classes**: bearing, imbalance, misalignment, normal
- **Rows**: True labels (actual conditions)
- **Columns**: Predicted labels (model predictions)
- **Color Scale**: Blue (darker = higher count)
- **Values**: Number of samples in each cell
- **Purpose**: Shows classification performance on training data

**Interpretation**:
- **Diagonal cells**: Correct predictions
  - High values (e.g., 25-30): Good classification
  - Low values: Poor classification for that class
- **Off-diagonal cells**: Misclassifications
  - Non-zero values: Confusion between classes
  - Example: If bearing→imbalance = 5, 5 bearing samples were misclassified as imbalance

**Expected Results** (Synthetic Data):
- Perfect diagonal: All classes correctly classified
- Off-diagonal zeros: No misclassifications
- 100% training accuracy

---

### Feature-Based Model Training

**Script**: `train_features.py`  
**Output Files**:
- `output/features_training_history.png`
- `output/features_training_confusion_matrix.png`

#### 1. Training History Plot

**File**: `output/features_training_history.png`

A 1×2 subplot grid (same structure as LSTM):

1. **Model Loss** (Left)
   - Training and validation loss over epochs

2. **Model Accuracy** (Right)
   - Training and validation accuracy over epochs

**Model Configuration**:
- Architecture: Dense (64) → Dense (32) → Dense (16) → Dense (4, softmax)
- Input: 18 statistical features (mean, std, min, max, RMS, peak-to-peak for each axis)
- Optimizer: Adam (learning_rate=0.001)
- Epochs: 50 (with early stopping, patience=10)
- Batch size: 32

#### 2. Training Confusion Matrix

**File**: `output/features_training_confusion_matrix.png`

- **Type**: 4×4 heatmap
- **Classes**: bearing, imbalance, misalignment, normal
- **Purpose**: Shows feature-based model performance on training data

**Comparison with LSTM**:
- Feature-based: Faster training, less memory
- LSTM: Better temporal pattern capture
- Both achieve high accuracy on synthetic data

---

## Testing Visualizations

### LSTM Model Testing

**Script**: `test_lstm.py`  
**Output Files**:
- `output/lstm_test_confusion_matrix.png`
- `output/lstm_test_probability_distribution.png`

#### 1. Test Confusion Matrix

**File**: `output/lstm_test_confusion_matrix.png`

- **Type**: 4×4 heatmap
- **Classes**: bearing, imbalance, misalignment, normal
- **Data**: Test set (unseen during training)
- **Purpose**: Evaluates model generalization to new data

**Interpretation**:
- **Perfect Classification**: All 8 samples per class correctly predicted
  - Diagonal: 8, 8, 8, 8
  - Off-diagonal: All zeros
- **Misclassifications**: Off-diagonal non-zero values
  - Indicates which conditions are confused
  - Helps identify similar patterns between conditions

**Expected Results** (Synthetic Data):
- 100% test accuracy
- Perfect diagonal matrix
- No misclassifications

#### 2. Probability Distribution Plot

**File**: `output/lstm_test_probability_distribution.png`

A 2×2 subplot grid showing probability distributions for each class:

1. **Bearing Condition** (Top Left)
   - Histogram of predicted probabilities for bearing class
   - X-axis: Predicted probability (0-1)
   - Y-axis: Frequency
   - Threshold line: Red dashed line at 0.5

2. **Imbalance Condition** (Top Right)
   - Probability distribution for imbalance class

3. **Misalignment Condition** (Bottom Left)
   - Probability distribution for misalignment class

4. **Normal Condition** (Bottom Right)
   - Probability distribution for normal class

**Purpose**: Shows model confidence for each class

**Interpretation**:
- **High probabilities (>0.8)**: Very confident predictions
- **Medium probabilities (0.5-0.8)**: Moderate confidence
- **Low probabilities (<0.5)**: Uncertain or incorrect predictions
- **Well-separated distributions**: Good model performance
- **Overlapping distributions**: Model uncertainty

**Expected Results** (Synthetic Data):
- Most probabilities close to 1.0 for correct class
- Clear separation between classes
- High confidence predictions

---

### Feature-Based Model Testing

**Script**: `test_features.py`  
**Output Files**:
- `output/features_test_confusion_matrix.png`
- `output/features_test_probability_distribution.png`

#### 1. Test Confusion Matrix

**File**: `output/features_test_confusion_matrix.png`

- **Type**: 4×4 heatmap
- **Classes**: bearing, imbalance, misalignment, normal
- **Purpose**: Feature-based model test performance

#### 2. Probability Distribution Plot

**File**: `output/features_test_probability_distribution.png`

- **Type**: 2×2 subplot grid
- **Structure**: Same as LSTM probability distribution
- **Purpose**: Feature-based model confidence visualization

**Comparison**:
- LSTM: May show slightly higher confidence (temporal patterns)
- Feature-based: May show more variability (statistical features)

---

## Validation Visualizations

**Script**: `validate.py`  
**Output Files**:
- `output/{condition}_sample_visualization.png` (per condition)
- `output/condition_comparison.png`

### 1. Sample Condition Visualization

**File**: `output/{condition}_sample_visualization.png`

Where `{condition}` is one of: `normal`, `bearing`, `imbalance`, `misalignment`

A 3×1 subplot grid showing 3-axis accelerometer data:

1. **Axial Acceleration (ax)** (Top)
   - X-axis: Time (seconds, 0-10)
   - Y-axis: Acceleration (g)
   - Color: Red
   - Shows vibration along motor shaft axis

2. **Radial Horizontal Acceleration (ay)** (Middle)
   - X-axis: Time (seconds)
   - Y-axis: Acceleration (g)
   - Color: Blue
   - Shows horizontal radial vibration

3. **Radial Vertical Acceleration (az)** (Bottom)
   - X-axis: Time (seconds)
   - Y-axis: Acceleration (g)
   - Color: Green
   - Shows vertical radial vibration

**Purpose**: Visualizes raw vibration data for a specific condition

**Usage**:
```bash
python validate.py visualize normal 0  # Visualize first normal sample
python validate.py visualize bearing 2  # Visualize third bearing sample
```

**Interpretation**:
- **Normal**: Balanced, low-amplitude vibration
- **Bearing**: Increased vibration, especially in radial axes
- **Misalignment**: Asymmetric patterns, phase differences
- **Imbalance**: High amplitude in radial directions

### 2. Condition Comparison Plot

**File**: `output/condition_comparison.png`

A 4×3 subplot grid comparing all conditions:

**Rows** (one per condition):
1. Normal
2. Bearing
3. Misalignment
4. Imbalance

**Columns** (one per axis):
1. Axial (ax) - Red
2. Radial Horizontal (ay) - Blue
3. Radial Vertical (az) - Green

**Purpose**: Side-by-side comparison of vibration patterns across all conditions

**Interpretation**:
- **Visual differences**: Each condition shows distinct patterns
- **Amplitude differences**: Imbalance typically highest, normal lowest
- **Pattern differences**: Temporal characteristics vary by condition

**Usage**:
```bash
python validate.py compare
```

---

## Plot Interpretation Guide

### Confusion Matrix Interpretation

#### Perfect Classification
```
        bearing  imbalance  misalignment  normal
bearing    8         0           0          0
imbalance  0         8           0          0
misalignment 0       0           8          0
normal     0         0           0          8
```
- **Meaning**: 100% accuracy, all samples correctly classified
- **Diagonal**: All values on diagonal
- **Off-diagonal**: All zeros

#### Typical Misclassification
```
        bearing  imbalance  misalignment  normal
bearing    7         1           0          0
imbalance  0         8           0          0
misalignment 0       1           7          0
normal     0         0           0          8
```
- **Meaning**: Some confusion between similar conditions
- **Bearing**: 1 sample misclassified as imbalance
- **Misalignment**: 1 sample misclassified as imbalance
- **Accuracy**: 30/32 = 93.75%

### Training History Interpretation

#### Good Training
- Loss decreases smoothly
- Accuracy increases steadily
- Train and validation curves close together
- Early stopping may trigger (patience reached)

#### Overfitting
- Training loss/accuracy better than validation
- Large gap between train and validation curves
- Validation metrics plateau or worsen

#### Underfitting
- Loss not decreasing
- Accuracy not improving
- Both train and validation perform poorly

### Probability Distribution Interpretation

#### High Confidence Model
- Distributions well-separated
- Most probabilities >0.8 for correct class
- Clear distinction between classes

#### Uncertain Model
- Overlapping distributions
- Many probabilities in 0.4-0.6 range
- Unclear class boundaries

### Feature-Based vs LSTM Comparison

| Aspect | Feature-Based | LSTM |
|--------|--------------|------|
| **Training Time** | ~30-60 seconds | ~2-5 minutes |
| **Memory Usage** | Lower | Higher |
| **Temporal Info** | Lost (statistical only) | Preserved |
| **Interpretability** | Higher (features) | Lower |
| **Accuracy** | High (95-100%) | Very High (100%) |

---

## Output Directory Structure

All CSV_TF plots are saved in `csv_tf/output/`:

```
csv_tf/output/
├── lstm_training_history.png
├── lstm_training_confusion_matrix.png
├── lstm_test_confusion_matrix.png
├── lstm_test_probability_distribution.png
├── features_training_history.png
├── features_training_confusion_matrix.png
├── features_test_confusion_matrix.png
├── features_test_probability_distribution.png
├── normal_sample_visualization.png
├── bearing_sample_visualization.png
├── imbalance_sample_visualization.png
├── misalignment_sample_visualization.png
└── condition_comparison.png
```

---

## Notes

- All plots are saved at 150 DPI for high quality
- Plots are displayed in interactive windows using `plt.show()`
- Plots are saved using `plt.savefig()` before display
- Color schemes are consistent:
  - Red: Axial (ax) or loss/error metrics
  - Blue: Radial horizontal (ay) or accuracy metrics
  - Green: Radial vertical (az)
  - Orange: Validation metrics (when overlaid with training)
- Grid lines and legends included for clarity
- Synthetic data typically shows perfect or near-perfect results
- Real-world data will show more variability and lower accuracy

---

## Quick Reference

### Generate Plots

**Training**:
```bash
../venv/Scripts/python.exe train_lstm.py      # LSTM training plots
../venv/Scripts/python.exe train_features.py  # Feature-based training plots
```

**Testing**:
```bash
../venv/Scripts/python.exe test_lstm.py       # LSTM test plots
../venv/Scripts/python.exe test_features.py   # Feature-based test plots
```

**Validation**:
```bash
../venv/Scripts/python.exe validate.py validate              # Check data structure
../venv/Scripts/python.exe validate.py visualize normal 0     # Visualize sample
../venv/Scripts/python.exe validate.py compare                # Compare conditions
```

### Expected File Sizes

- Training history plots: ~50-100 KB
- Confusion matrices: ~30-50 KB
- Probability distributions: ~60-80 KB
- Sample visualizations: ~40-60 KB
- Condition comparison: ~80-120 KB

---

## Troubleshooting

### Plots Not Displaying
- Ensure matplotlib backend supports GUI (not 'Agg')
- Check if `plt.show()` is called after `plt.savefig()`
- Verify display environment (X11 on Linux, GUI on Windows/Mac)

### Plots Not Saving
- Check `output/` directory exists (created automatically)
- Verify write permissions
- Check disk space

### Poor Plot Quality
- Increase DPI: `plt.savefig(..., dpi=300)`
- Adjust figure size: `plt.figure(figsize=(width, height))`
- Use vector formats: `.svg` or `.pdf` for scalability

